{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on the type of questions being asked\n",
    "- Diving the dataset based on duplicate or non-duplicate value\n",
    "- Create a sample positive and negative series of sentences to train the data\n",
    "- Run NaiveBaiseClassifier to classify words from our dataset into positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get the required imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#getting current working directory\n",
    "b = os.getcwd()\n",
    "\n",
    "df = pd.read_csv(b+\"/\"+\"Data/questions.csv\", usecols=[3,4,5]).fillna(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a subset of dataframes based on the similarity of questions\n",
    "df1 = df[df['is_duplicate']== 0]\n",
    "df2 = df[df['is_duplicate']== 1]\n",
    "#df = df[df.question1 != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255045"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#resetting the indexes of both similar and dissmilar dataframes\n",
    "df1 = df1.reset_index()\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a list of all questions\n",
    "questions = []\n",
    "\n",
    "for i in range(0, len(df1)):\n",
    "    #for non unique questions add both the questions to the list\n",
    "    questions.append(df1['question1'][i])\n",
    "    questions.append(df1['question2'][i])\n",
    "    \n",
    "for i in range(0,len(df2)):\n",
    "    #for similar questions add only first question to the list\n",
    "    questions.append(df2['question1'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qs_list = pd.Series(df['question1'].tolist() + df['question2'].tolist()).astype(str)\n",
    "\n",
    "qs1_lower = []\n",
    "for questions in qs_list:\n",
    "    qs1_lower.append(questions.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv(b+\"/\"+\"Data/positive.csv\")\n",
    "negative = pd.read_csv(b+\"/\"+\"Data/negative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808702"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Analyzing if comments are positive or negative\n",
    "\n",
    "#creating temporary counters\n",
    "o_main_pos = 0\n",
    "o_main_neg = 0\n",
    "o_main_neu = 0\n",
    "\n",
    "#lists to store questions\n",
    "posi_com = []\n",
    "nega_com = []\n",
    "neu_com = []\n",
    "\n",
    "#iterating through the dataset\n",
    "for qs in qs1_lower:\n",
    "    count_pos = 0\n",
    "    count_neg = 0\n",
    "    \n",
    "    #splitting the question into words\n",
    "    for word in qs.split():\n",
    "        if word in  positive:\n",
    "            count_pos = count_pos + 1\n",
    "        elif word in negative:\n",
    "            count_neg = count_neg + 1 \n",
    "            \n",
    "        #check which count is more and then add it to the respective list\n",
    "        if count_pos > count_neg:\n",
    "            posi_com.append(qs)\n",
    "            o_main_pos = o_main_pos+1\n",
    "        elif count_pos < count_neg:\n",
    "            nega_com.append(qs)\n",
    "            o_main_neg = o_main_neg+1\n",
    "        else:\n",
    "            neu_com.append(qs)\n",
    "            o_main_neu = o_main_neu+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive questions:\n",
      "99\n",
      "Number of negative questions:\n",
      "0\n",
      "Number of neutral questions:\n",
      "8945317\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of positive questions:\")\n",
    "print(len(posi_com))\n",
    "print(\"Number of negative questions:\")\n",
    "print(len(nega_com))\n",
    "print(\"Number of neutral questions:\")\n",
    "print(len(neu_com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Setiment Analysis using classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a list of positive sets and assigning them positive value\n",
    "#pos_qs = [('love this car', 'positive'),\n",
    "              #('This view is amazing', 'positive'),\n",
    "              #('I feel great this morning', 'positive'),\n",
    "              #('I am so excited about the concert', 'positive'),\n",
    "              #('He is my best friend', 'positive')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a list of negative sets and assigning them positive value\n",
    "#neg_qs = [('I do not like this car', 'negative'),\n",
    "              #('This view is horrible', 'negative'),\n",
    "              #('I feel tired this morning', 'negative'),\n",
    "              #('I am not looking forward to the concert', 'negative'),\n",
    "              #('He is my enemy', 'negative')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#removing words with length lesser than 3 (like is,in etc) and changing them to lowercase\n",
    "#qs = []\n",
    "#for (words, sentiment) in pos_qs + neg_qs:\n",
    "    #words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    #qs.append((words_filtered, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extracting words from the dataset\n",
    "#def get_words_in_qs(qs):\n",
    "   # all_words = []\n",
    "    #for (words, sentiment) in qs:\n",
    "        #all_words.extend(words)\n",
    "    #return all_words\n",
    "\n",
    "#use feqDist function to get the frequency of words in the list\n",
    "#def get_word_features(wordlist):\n",
    "    #wordlist = nltk.FreqDist(wordlist)\n",
    "    #word_features = wordlist.keys() #extracting the keys from the dataset i.e the words not their frequency\n",
    "    #return word_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#word_features = get_word_features(get_words_in_qs(qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def extract_features(document):\n",
    "    #document_words = set(document)\n",
    "    #features = {}\n",
    "    #for word in word_features:\n",
    "        #print('i am here')\n",
    "        #features['contains(%s)' % word] = (word in document_words)\n",
    "    #print(features)    \n",
    "    #return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_tweet_sentiment(self, tweet):\n",
    "        # create TextBlob object of passed tweet text\n",
    "        #analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        #if analysis.sentiment.polarity > 0:\n",
    "            #return 'positive'\n",
    "        #elif analysis.sentiment.polarity == 0:\n",
    "            #return 'neutral'\n",
    "        #else:\n",
    "            #return 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using NaiveBaiseClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_set = nltk.classify.apply_features(extract_features, qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from nltk.probability import ELEProbDist, FreqDist\n",
    "#from nltk import NaiveBayesClassifier\n",
    "\n",
    "#def train(labeled_featuresets, estimator=ELEProbDist):\n",
    "    #Create the P(label) distribution\n",
    "    #label_probdist = estimator(label_freqdist)\n",
    "    #Create the P(fval|label, fname) distribution\n",
    "    #feature_probdist = {}\n",
    "    #return NaiveBayesClassifier(label_probdist, feature_probdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running the NaiveBaiseClassifier on our dataset\n",
    "#adding the sentiment extracted to a new list\n",
    "#sentiment = []\n",
    "#for sentence in questions:\n",
    "    #sentiment.append(classifier.classify(extract_features(sentence.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "#questions = pd.DataFrame(questions)\n",
    "#sentiment = pd.DataFrame(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merging the two dataset in one\n",
    "#sent_analysis = pd.concat([questions, sentiment], axis=1)\n",
    "#sent_analysis.columns = ['questions','sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filtering the questions with negative sentiments\n",
    "#neg = sent_analysis[sent_analysis['sentiment']=='negative']\n",
    "#neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sent_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
