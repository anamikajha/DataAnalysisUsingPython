{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "- Read Gutenberg and Webtext Data\n",
    "- Find out top 5 words that were used by Shakespeare but are not used currently\n",
    "- Take top 50 words from all Shakespeare and webtext files\n",
    "- Get top 5 elements from the words not in use today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "corpus_list_1 = nltk.corpus.gutenberg.fileids()\n",
    "corpus_list_2 = nltk.corpus.webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firefox.txt',\n",
       " 'grail.txt',\n",
       " 'overheard.txt',\n",
       " 'pirates.txt',\n",
       " 'singles.txt',\n",
       " 'wine.txt']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sh_words_1 = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "#sh_words_2 = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "#sh_words_3 = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "\n",
    "#getting all Shakespeare files\n",
    "sh_list = corpus_list_1[14:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#getting all the words in all 3 Shakespeare files\n",
    "total_words_sh = nltk.corpus.gutenberg.words('shakespeare-caesar.txt') + nltk.corpus.gutenberg.words('shakespeare-hamlet.txt') + nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_words_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopWord = stopwords.words('english')\n",
    "len(stopWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_word_list = total_words_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converting to lowercase\n",
    "#l1 = [x.lower() for x in total_words_sh if x not in stopWord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting to lowercase\n",
    "allWordsLowerCase = [item.lower() for item in total_words_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = [x.lower() for x in allWordsLowerCase if x not in stopWord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string \n",
    "l2 = [x for x in l1 if x not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordFreq = {} \n",
    "for w in l2:\n",
    "    if w in wordFreq:\n",
    "        wordFreq[w] += 1\n",
    "    else:\n",
    "        wordFreq[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorting the dictionary\n",
    "import operator\n",
    "wordFreq_sorted = sorted(wordFreq.items(),key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haue 448\n",
      "ham 337\n",
      "thou 312\n",
      "shall 300\n",
      "lord 293\n",
      "come 232\n",
      "king 231\n",
      "enter 230\n",
      "good 218\n",
      "let 217\n",
      "thy 202\n",
      "caesar 193\n",
      "vs 184\n",
      "know 176\n",
      "thee 174\n",
      "would 170\n",
      "like 162\n",
      "brutus 162\n",
      "vpon 162\n",
      "bru 153\n",
      "well 152\n",
      "hath 144\n",
      "selfe 143\n",
      "man 139\n",
      "may 138\n",
      "macb 137\n",
      "yet 136\n",
      "heere 135\n",
      "must 130\n",
      "say 130\n",
      "tis 129\n",
      "th 125\n",
      "make 119\n",
      "speake 119\n",
      "loue 119\n",
      "giue 118\n",
      "see 116\n",
      "time 115\n",
      "sir 114\n",
      "night 114\n",
      "one 112\n",
      "st 110\n",
      "cassi 107\n",
      "ile 106\n",
      "doe 103\n",
      "go 100\n",
      "hamlet 100\n",
      "men 96\n",
      "hor 95\n",
      "vp 94\n"
     ]
    }
   ],
   "source": [
    "# getting top 50 words of Shakespeare\n",
    "for word in wordFreq_sorted[:50]:\n",
    "    print(word[0],word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_50 = wordFreq_sorted[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using same process for word file\n",
    "from nltk.corpus import webtext\n",
    "allWebFiles = webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in allWebFiles:\n",
    "    allWordWeb = webtext.words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_words = webtext.words('firefox.txt') + webtext.words('grail.txt') + webtext.words('overheard.txt') + webtext.words('pirates.txt') + webtext.words('singles.txt') + webtext.words('wine.txt')\n",
    "\n",
    "common_words_lowercase = [item.lower() for item in common_words]\n",
    "common_words_nostopwords = [x.lower() for x in common_words_lowercase if x not in stopWord]\n",
    "all_common_words = [x for x in common_words_nostopwords if x not in string.punctuation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_word_dict = {}\n",
    "for w in all_common_words:\n",
    "    if w in common_word_dict:\n",
    "        common_word_dict[w] += 1\n",
    "    else:\n",
    "        common_word_dict[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorting the dictionary\n",
    "common_word_dict = sorted(common_word_dict.items(),key=operator.itemgetter(1),reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl 2956\n",
      "guy 2751\n",
      "1 2261\n",
      "2 1709\n",
      "like 1696\n",
      "... 1542\n",
      "man 1075\n",
      "know 1025\n",
      "woman 998\n",
      "yeah 895\n",
      "page 887\n",
      "firefox 879\n",
      "get 869\n",
      "new 790\n",
      "chick 714\n",
      "one 700\n",
      "oh 682\n",
      "open 679\n",
      "window 670\n",
      "good 644\n",
      "bookmarks 598\n",
      "teen 587\n",
      "well 586\n",
      "firebird 583\n",
      "cell 577\n",
      "right 576\n",
      "go 564\n",
      "work 537\n",
      "bar 536\n",
      "menu 530\n",
      "tab 529\n",
      "lady 524\n",
      "toolbar 518\n",
      "*** 498\n",
      "boy 488\n",
      "want 485\n",
      "browser 484\n",
      "think 484\n",
      "jack 483\n",
      "bookmark 482\n",
      "old 475\n",
      "really 473\n",
      "going 460\n",
      "download 442\n",
      "url 440\n",
      "back 434\n",
      "time 432\n",
      "black 422\n",
      "manager 420\n",
      "little 419\n"
     ]
    }
   ],
   "source": [
    "# getting top 50 words of common words\n",
    "for word in common_word_dict[:50]:\n",
    "    print(word[0], word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_50_common_words = common_word_dict[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = list(set(top_50).difference(top_50_common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list3 = [item[0] for item in top_50 if item[0] not in top_50_common_words[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_top_50 = [i[0][0:] for i in top_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_top_50_common_words = [i[0][0:] for i in top_50_common_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unused_words = [item for item in new_top_50 if item not in new_top_50_common_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haue\n",
      "ham\n",
      "thou\n",
      "shall\n",
      "lord\n"
     ]
    }
   ],
   "source": [
    "# getting top 5 unused words\n",
    "for word in unused_words[:5]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#getting all the words in all 3 Shakespeare files\n",
    "\n",
    "#total_words_sh = {}\n",
    "#for f in sh_list:\n",
    "    #c=1\n",
    "    #w = nltk.corpus.gutenberg.words(f)\n",
    "    #printing total no of words in each file\n",
    "    #print('total words in', c,  'file=', len(w))\n",
    "    #c += 1\n",
    "    #concatenating words from all 3 files\n",
    "    #for word in w:\n",
    "      #  if word.isalpha():\n",
    "         #   if word in total_words_sh:\n",
    "        #     total_words_sh[word] +=1\n",
    "            #else:\n",
    "               # total_words_sh[word] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(total_words_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting all the characters in all webtext file\n",
    "\n",
    "#total_words_wb = {}\n",
    "#for f in corpus_list_2:\n",
    "#    y=nltk.corpus.webtext.words(f)\n",
    "#    print('total words in file=', len(y))\n",
    "#    for word in y:\n",
    "#        if word.isalpha():\n",
    "#            if word in total_words_wb:\n",
    " #               total_words_wb[word] +=1\n",
    "#          else:\n",
    "#                total_words_wb[word] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorting shakespeares words based on mostly used\n",
    "#import operator\n",
    "#total_words_sh = sorted(total_words_sh.items(),key=operator.itemgetter(1),reverse=True)\n",
    "#total_words_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorting webtexts words based on mostly used\n",
    "#import operator\n",
    "#total_words_wb = sorted(total_words_wb.items(),key=operator.itemgetter(1),reverse=True)\n",
    "#total_words_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
